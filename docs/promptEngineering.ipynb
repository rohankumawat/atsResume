{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import PyPDF2 as pdf\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_file = \"../machine_learning_resume_speechmatics.pdf\"\n",
    "\n",
    "reader=pdf.PdfReader(uploaded_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\n",
    "for page in range(len(reader.pages)):\n",
    "    page=reader.pages[page]\n",
    "    text+=str(page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rohan Kumawat\\n+44-7867233460 |kumawatrohan@gmail.com |LinkedIn |Github |Medium |Newsletter\\nAs amachine learning engineer , I am seeking a challenging role where I can bring my passion for Machine Learning and\\nSpeech Recognition to the forefront using my Python, SQL, and Tensor Flow skills.\\nEducation\\nUniversity of Glasgow Glasgow, Scotland\\nMasterâ€™s in Robotics and A.I. Sep. 2022 â€“ May 2024\\nG.D. Goenka University Gurgaon, India\\nBachelorâ€™s of Technology in Computer Science Engineering Aug. 2018 â€“ May 2022\\nExperience\\nWorkshop Mar 2021\\nSpotify Recommendation Engine and API\\nâ€¢Led a detailed Spotify Recommendation System workshop, focusing on API integration and filtering techniques.\\nâ€¢Demystified API complexities in data analysis for diverse audiences, enhancing comprehension of recommendation\\nsystems.\\nâ€¢Facilitated effective knowledge transfer in data science, empowering attendees to implement recommendation\\nengines in varied scenarios.\\nInternship Feb 2020 â€“ Oct 2020\\nLinux World Informatics\\nâ€¢Engineered solutions and integrated a variety of technologies such as Docker, RedHat, Python, MLOps, AWS\\nCloud, GCP Cloud, and Flutter during internship, applying them in real-world, industrial projects.\\nâ€¢Absorbed a vast array of technologies demonstrating a strong capability for quick learning in high-tech\\nenvironments\\nâ€¢Synthesized diverse technologies in project development and honed my approach to solving industrial problems,\\nwhile mastering time management\\nProjects\\nPredicting Central Neuropathic Pain |Python, Pandas Nov 2022 â€“ Dec 2022\\nâ€¢Developed an advanced machine learning model to predict Central Neuropathic Pain in patients, utilizing Python\\nand various feature engineering methods (Filter, Wrapper, Embedded) to handle high-dimensional EEG data.\\nâ€¢Overcame challenges associated with high-dimensional data and model overfitting by implementing and comparing\\ndifferent feature selection methods, achieving enhanced model accuracy and reliability.\\nâ€¢Efficaciously enhanced Logistic Regression and Linear SVM classifiers using feature engineering, showcasing the\\npivotal role of strategic feature selection in predictive model performance.\\nSpotify Songs Data Analysis |Python, Streamlit, Plotly, Spotify API Jan 2022 â€“ Apr 2022\\nâ€¢Orchestrated the development of a Python-based web application for visualizing Spotify song and artist data,\\nutilizing the Spotify API for data acquisition and presentation.\\nâ€¢Excelled as a full-stack developer, skillfully integrating data analysis, web development, and API utilization to\\ndeliver a highly functional data analysis tool.\\nâ€¢Surmounted Spotify API challenges, including data extraction limits and automation hurdles, showcasing resilience\\nand innovative problem-solving abilities.\\nMLops Fashion MNIST |Python, GitHub, RedHat, Jenkins, Keras Apr 2020 â€“ June 2021\\nâ€¢Orchestrated the integration of MLOps using Docker and Jenkins to automate the machine learning model\\ndevelopment and deployment process.\\nâ€¢Navigated complexities in model training by automating hyperparameter selection and implementing a fail-safe for\\nsuboptimal model performance.\\nâ€¢Achieved a significant increase in model accuracy and efficiency, ensuring 95 percent accuracy threshold compliance\\nand enhanced pipeline scalability.\\nTechnical Skills\\nSkill-Set : Python, C++, SQL, NoSQL, Machine Learning, Natural Language Processing\\nDeployment Tools : Git, Github, Docker, Google Cloud Platform, AWS, Linux\\nLibraries : Pandas, NumPy, Matplotlib, Seaborn, Plotly, SKLearn, Streamlit, Keras'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = \"\"\"\n",
    "Department \n",
    "\n",
    "Moodyâ€™s Analytics Quantum Computing team explores, researches, and implements quantum computing and communications solutions across the different organizational units of the company.\n",
    "\n",
    "Role/Responsibilities\n",
    "\n",
    "This group objective is to evaluate how quantum computing can disrupt our industry and Moodyâ€™s products in the market, evaluate the industry maturity, establish partnerships, and position Moodyâ€™s as a referent in the quantum computing sector for finance. The team creates proofs of concept and final applications that are embedded in the current classical products. Leverages our state-of-the-art financial models and our extensive datasets across the company and liaises with the different stakeholders for its productization.\n",
    "\n",
    "In this role you will be hands-on and you will evaluate current literature, participate in the research community, and develop solutions in partnership with domain experts across the company. You are expected to have an elevated level of autonomy, capacity to learn new skills and domains including advanced scientific and technical concepts quickly and with minimal direction, along with demonstrated experience in teaching others. We are looking for a person who is passionate about quantum computing and its implications on the financial industry.\n",
    "\n",
    "Strong technical skills and a demonstrated ability to learn new concepts is important for this position. Experience in both quantum computing and software development is essential.\n",
    "\n",
    "Your Role will:\n",
    "\n",
    "Â» Own and lead the conception and delivery of novel solutions to problems faced by internal project teams.\n",
    "\n",
    "Â» Develop new and continually improve existing Quantum Algorithms for specific applications, in the team and in collaboration with external partners. Lead and manage the quantum innovation portfolio and pipeline, understanding the internal and external customer and business needs in order to recommend solutions where a quantum or quantum inspired approach may be optimal.\n",
    "\n",
    "Â» Provide guidance to other groups throughout Moodyâ€™s Analytics on best practices and advanced techniques.\n",
    "\n",
    "Â» Contribute to Moodyâ€™s IP by developing innovative solutions and use cases in collaboration with our partners and clients. The goal is to transform scientific research into business value.\n",
    "\n",
    "Â» Write white papers and build and maintain relationships with the external academic community and business community.\n",
    "\n",
    "Â» Consistently scan the market / competitors / partners / research, lead client engagements to understand challenges that they are trying to address, and meet with external partners to bring new ideas and technologies to Moodyâ€™s Analytics.\n",
    "\n",
    "Â» Represent the company as a technical expert on quantum computing and present research findings to audiences internally and externally. Demonstrate thought leadership as it relates to QC, and actively seek ways to build MAâ€™s â€œdata and risk expertiseâ€ reputation externally (white papers, speaking panels, etc.). Partner with other ML groups inside the company to find hybrid solutions and benchmarks.\n",
    "\n",
    "Additional Requirements:\n",
    "\n",
    "Â» Performing statistical analysis on financial, climate and other type of data.\n",
    "\n",
    "Â» Predictive analytics\n",
    "\n",
    "Â» Conceptual modelling\n",
    "\n",
    "Â» Creating examples, prototypes, demonstrations\n",
    "\n",
    "Â» Have the ability to work in a fast-paced, competitive and multidisciplinary environment\n",
    "\n",
    "Â» Be able to keep up with a landscape where new data/algorithms keeps flowing in rapidly and the world is constantly changing\n",
    "\n",
    "Â» Ability to work equally well as part of a team and autonomously\n",
    "\n",
    "Qualifications\n",
    "\n",
    "Â» BSc in Computer Science, Engineering, Physics, Math, or related field.\n",
    "\n",
    "Â» MSc, PhD in Computer Science, Engineering, Physics, Math, or related field.\n",
    "\n",
    "Â» Advanced knowledge of Python, scientific computing tools and cloud computing are required.\n",
    "\n",
    "Â» Previous experience with software best practices, including continuous-integration pipelines, unit testing, code review.\n",
    "\n",
    "Â» Working knowledge of quantum computing algorithms and applications. Hybrid classical/quantum algorithms are included.\n",
    "\n",
    "Â» Experience with Machine Learning / AI algorithms.\n",
    "\n",
    "Â» Demonstrated knowledge and experience with Tensor Network based numerical simulation methods is a plus, with a focus on ML, optimization, function approximation and dimensionality reduction.\n",
    "\n",
    "Â» Familiarity with Tensor Network libraries and/or relevant functions (ITensor, cuTensorNet, TeNPy, tntorch, scikit-tt or other toolboxes) is a plus.\n",
    "\n",
    "Â» No prior familiarity with financial use cases required. Experience with financial asset allocation, predictive analytics with financial time series and risk modeling is a plus.\n",
    "\n",
    "Â» If you have open-source contributions or your own code repositories will be a plus. .\n",
    "\n",
    "Â» Experience in technical writing in a scientific or technical field. Demonstrated research ability.\n",
    "\n",
    "Â» Self-motivated with a willingness to learn.\n",
    "\n",
    "Â» Must be results-oriented and have a proven ability to get things done through people, including those not under direct management.\n",
    "\n",
    "Â» High level of professionalism.\n",
    "\n",
    "Moodyâ€™s is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, sexual orientation, gender expression, gender identity or any other characteristic protected by law.\n",
    "\n",
    "Candidates for Moodyâ€™s Corporation may be asked to disclose securities holdings pursuant to Moodyâ€™s Policy for Securities Trading and the requirements of the position. Employment is contingent upon compliance with the Policy, including remediation of positions in those holdings as necessary.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "Hey Act Like a skilled or very experience ATS(Application Tracking System)\n",
    "with a deep understanding of tech field,software engineering,data science ,data analyst\n",
    "and big data engineer. Your task is to evaluate the resume based on the given job description.\n",
    "You must consider the job market is very competitive and you should provide \n",
    "best assistance for improving thr resumes. Assign the percentage Matching based \n",
    "on Jd and\n",
    "the missing keywords with high accuracy\n",
    "resume:{text}\n",
    "description:{jd}\n",
    "\n",
    "I want the response in one single string having the structure\n",
    "{{\"JD Match\":\"%\",\"MissingKeywords:[]\",\"Profile Summary\":\"\"}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(jd = jd)\n",
    "chain = prompt | ChatOpenAI(model=\"gpt-4-1106-preview\") | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"JD Match\":\"65%\",\"MissingKeywords\":[\"Quantum Computing\", \"Quantum Algorithms\", \"Statistical Analysis\", \"Predictive Analytics\", \"Conceptual Modelling\", \"Financial Data Analysis\", \"Tensor Network\", \"ITensor\", \"cuTensorNet\", \"TeNPy\", \"tntorch\", \"scikit-tt\", \"Financial Asset Allocation\", \"Financial Time Series\", \"Risk Modeling\", \"Technical Writing\", \"Research\"], \"Profile Summary\":\"Rohan Kumawat presents a strong background in machine learning, data science, and software engineering with hands-on experience in developing machine learning models, data analysis, and MLOps. His technical skill set and project work indicate a proficiency with Python, various ML libraries, and cloud technologies. However, his resume lacks specific experience and skills in quantum computing, which is a core requirement of the job description. Additionally, there is no mention of experience with financial data analysis or statistical methods pertinent to finance. To improve his match for the role, Rohan should seek to gain knowledge and experience in quantum computing, particularly in the context of financial applications, and demonstrate an understanding of financial datasets and risk modeling. Technical writing and research experience, particularly with published work, would also bolster his qualifications for the role.\"}"
     ]
    }
   ],
   "source": [
    "for token in chain.stream({\"text\": text}):\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = \"\"\"\n",
    "About You\n",
    "\n",
    "You are an experienced Machine Learning Engineer who can help us advance our automatic speech recognition (ASR) and is excited to build the voice interfaces of the future. We are betting big on scaling models so you will be working with millions of hours of audio and billion parameter models which train across dozens of GPUs. Itâ€™s all about finding the bottlenecks across our 30+ languages and targeting our efforts to understand every voice. Our main research focus is large-scale Self-supervised Learning and a practical focus on building state-of-the-art speech pipelines.\n",
    "\n",
    "An average day might include working on\n",
    "\n",
    "Scaling self-supervised learning models across hundreds of GPUs in the cloud \n",
    "Experimenting with distillation or quantisation to speed up our models at runtime \n",
    "Comparing compute efficiencies of architectures such as a transformer and the impact on WER \n",
    "Developing a new product, such as Language ID, from training the model all the way to shipping it to production\n",
    "Advancing end-to-end speech models in PyTorch such as the RNN Transducer\n",
    "Giving a journal club on a recent paper such as DALLE-2 \n",
    "\n",
    "We aim to get you onboarded and started on something like this in your first few days. In addition, having a very collaborative culture, you will often be pair programming with a colleague on streamlining our production ML pipelines, reviewing other folksâ€™ code and suggesting new ways to tackle a tough real time factor (RTF) optimisation problem as well as brainstorming novel approaches for analysing model predictions with the team.\n",
    "\n",
    " Youâ€™ll want to join our team if you\n",
    "\n",
    "Want to learn more about speech recognition and representational learning \n",
    "Are results driven, like moving fast and keeping things simple \n",
    "Love working in collaborative and ambitious teams \n",
    "Have a growth mindset and love to develop yourself and others \n",
    "Enjoy solving challenging problems and digging into a stack of unfamiliar code\n",
    "Love optimising code\n",
    "\n",
    "You May Have Experience In Some Of The Following\n",
    "\n",
    "A GitHub portfolio demonstrating personal ML projects \n",
    "Large scale distributed model training\n",
    "Deep learning and Pytorch\n",
    "Language modelling and acoustic modelling\n",
    "Comfortable on the command line and shell scripting\n",
    "ETL pipelines in Python (we like Prefect and Airflow)\n",
    "Speaking multiple languages or a background in linguistics \n",
    "\n",
    "About Us\n",
    "\n",
    "Speechmatics has collaborative office spaces in the UK, with teams also located in the Czech Republic, India and the US. Our speech-to-text software is the worldâ€™s most accurate, regularly winning customers from Google, Amazon and Microsoft (learn more in our whitepapers here). We believe we are the UKâ€™s most exciting ML start-up and have grand ambitions for the future of speech tech. Come and join our mission to build perfect speech recognition to understand every voice!\n",
    "\n",
    "What We Can Offer You\n",
    "\n",
    "Speechmatics is a collective team of ambitious, problem solvers and thought-leaders paving the way for inclusion in speech recognition technology ðŸ—£ðŸŽ™.\n",
    "\n",
    "No matter what stage of your career you're at - from paid internships and first-job opportunities through to management and senior positions - we'll support you with the training and development ðŸ‹ï¸ needed to reach your career aspirations with us. There really is no shortage of opportunities here for you to get involved and collaborate with those around you to deliver your best work ðŸ“ˆ.\n",
    "\n",
    "When you become part of the Speechmatics Team we work hard to make sure you do your best work with us ðŸ’ª, while also having a good time doing it ðŸ˜†. With our Focus Fridays you get an undisturbed day of focus ðŸ§˜â€â™€ï¸, offset with Together Tuesdays when we have our team meetings ðŸ‘«.\n",
    "\n",
    "We offer incredibly flexible working ðŸ¤¸, regular company lunches, and birthday celebrationsðŸŽ‰. But that's not all. We've spoken to our teams to find out what they want. From Private Medical ðŸ¥ and Dental ðŸ¦· for you and your family, through to global working opportunities ðŸŒŽ, a generous holiday allowance ðŸ and pension/401K matching ðŸªº, we want to make sure our employees and their families are looked after. Every employee will receive a working from home allowance for tech or home office equipment (on top of your choice of laptop/ Mac, screen and accessories of course) ðŸ§‘â€ðŸ’»!\n",
    "\n",
    "We support people to work wherever they work best. But we also understand the importance of coming together to collaborate, socialise and build relationships. Individuals and teams are free to decide what works for them.\n",
    "\n",
    "Who We Are\n",
    "\n",
    "Speechmatics is the leading expert in Speech Intelligence, and uses AI and Machine Learning to unlock business value in human speech worldwide ðŸ—£ðŸŽ™. We work with an amazing mix of global companies ðŸŒŽ, and our technology can integrate into our customers stack irrespective of their industry or use case â€“ making it the go-to solution to harness useful information from speech. We have recently raised $62 million at Series B and continue to grow positively ðŸŒ».\n",
    "\n",
    "Joining us means working with some of the smartest minds around the world ðŸ¤¯, focused on cutting-edge projects and deploying the latest techniques to disrupt the market. We believe in putting people first ðŸ¥°; weâ€™ll do all we can to help you develop your skills and give you the tools you need to thrive ðŸ“ˆ. We support people to work wherever they work best and also understand the importance of coming together to collaborate, socialise and build relationships ðŸ™Œ.\n",
    "\n",
    "This is only the beginning; weâ€™re looking for amazing people like you to continue our journeyâ€¦ ðŸš€\n",
    "\n",
    "At Speechmatics, our mission has always been to â€˜Understand Every Voiceâ€™.\n",
    "\n",
    "We believe that recruiting talent with diverse experiences, perspectives and backgrounds encourages people to think differently and be more creative.\n",
    "\n",
    "We welcome difference whether itâ€™s gender, gender identity or expression, race, disability, age, sexual orientation, religion or belief, marital status, national origin, veteran status, or pregnancy and maternity status; so please be yourself!\n",
    "\n",
    "For more information on us, please visit our website and follow Speechmatics on our social channels via Twitter,â€¯Facebook,â€¯LinkedIn,â€¯andâ€¯YouTube.\n",
    "\n",
    "We rely on legitimate interest as a legal basis for processing personal information under the GDPR for purposes of recruitment and applications for employment.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(jd = jd)\n",
    "chain = prompt | ChatOpenAI(model=\"gpt-4-1106-preview\") | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"JD Match\":\"70%\",\"MissingKeywords\":[\"Self-supervised Learning\",\"PyTorch\",\"RNN Transducer\",\"DALLE-2\",\"transformer architectures\",\"Distillation\",\"Quantisation\",\"compute efficiencies\",\"WER (Word Error Rate)\",\"Language ID\",\"real time factor (RTF) optimisation\",\"Prefect\",\"Airflow\",\"shell scripting\",\"Language modelling\",\"acoustic modelling\",\"linguistics\"],\"Profile Summary\":\"Rohan Kumawat has a strong foundation in machine learning and data science with a Master's degree in Robotics and A.I. and a Bachelor's in Computer Science Engineering. His technical skills include Python, SQL, ML, and various libraries and deployment tools, aligning with the requirements of a Machine Learning Engineer. He has practical experience with machine learning projects, MLOps, and has demonstrated the ability to quickly absorb new technologies. However, his experience with speech recognition, PyTorch, and specifics of the job description such as working with large-scale models, self-supervised learning, and certain ML techniques is not evident in his resume. To improve his candidacy, he may want to highlight any relevant experiences or coursework related to ASR, familiarity with PyTorch, and his understanding of the listed ML techniques and tools.\"}"
     ]
    }
   ],
   "source": [
    "for token in chain.stream({\"text\": text}):\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_file = \"../machine_learning_resume.pdf\"\n",
    "\n",
    "reader=pdf.PdfReader(uploaded_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\n",
    "for page in range(len(reader.pages)):\n",
    "    page=reader.pages[page]\n",
    "    text+=str(page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = \"\"\"\n",
    "Responsibilities\n",
    "TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. \n",
    "\n",
    "Why Join Us \n",
    "At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok. \n",
    "\n",
    "Regardless of the function you choose to specialise in, our graduate roles will enable you to participate in meaningful and innovative projects. Your potential for growth at TikTok is limitless. Join us to enhance your skill set and develop your network in the tech industry. \n",
    "\n",
    "This role sits within our TikTok recommendation team. The team is responsible for developing state-of-the-art machine learning models and strategies to improve user consumption experience, inspire creativity and build a fair and flourishing ecosystem. \n",
    "\n",
    "Within this role, you will: - Build industry-leading recommendation systems, improving user experience, content ecosystem and platform security - Develop state-of-the-art machine learning models to solve problems at TikTok scale - Systematically develop product strategy with strong analytical and impact-driven mindset - Work with TikTok cross functional teams to grow TikTok in important regional markets\n",
    "\n",
    "Qualifications\n",
    "\n",
    "- Currently enrolled in a Bachelors or Masters degree, graduating in 2024\n",
    "- Studying computer science, engineering or a related technical discipline\n",
    "- Interest in at least one of the following areas: machine learning, data mining, algorithms\n",
    "- Great communication and teamwork skills\n",
    "- Passionate about techniques and solving challenging problems\n",
    "- The start date for the program will be September 2024\n",
    "- Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment \n",
    " \n",
    "TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(jd = jd)\n",
    "chain = prompt | ChatOpenAI(model=\"gpt-4-1106-preview\") | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"JD Match\":\"75%\",\"MissingKeywords\":[\"data mining\",\"algorithms\",\"cross-functional teamwork\",\"regional market strategies\",\"platform security\"],\"Profile Summary\":\"Rohan Kumawat's resume indicates a strong foundation in machine learning engineering with hands-on experience in recommendation systems and a variety of machine learning projects. He has a solid technical skill set relevant to the job description, including Python, SQL, and experience with TensorFlow, which aligns with the requirements for developing machine learning models at TikTok. His education background with a Master's in Robotics and A.I. is well-suited for the role. However, there are some missing keywords that are crucial for the job at TikTok, such as experience in data mining, algorithms, and an understanding of platform security. Additionally, evidence of cross-functional teamwork and strategies for regional market growth are not explicitly mentioned, which are important for the role that collaborates with cross-functional teams at TikTok. Enhancing the resume to include these elements would likely improve the match percentage.\"}"
     ]
    }
   ],
   "source": [
    "for token in chain.stream({\"text\": text}):\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (0.0.16)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss-cpu-1.7.4.tar.gz (57 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: langchain-openai in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (0.0.5)\n",
      "Requirement already satisfied: tiktoken in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (0.5.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from langchain-community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from langchain-community) (3.9.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from langchain-community) (0.6.3)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from langchain-community) (0.1.16)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from langchain-community) (0.0.84)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from langchain-community) (1.26.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from langchain-openai) (1.10.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from langchain-core<0.2,>=0.1.16->langchain-community) (4.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from langchain-core<0.2,>=0.1.16->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from langchain-core<0.2,>=0.1.16->langchain-community) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from langchain-core<0.2,>=0.1.16->langchain-community) (2.5.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.26.0)\n",
      "Requirement already satisfied: sniffio in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.16->langchain-community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.16->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.16->langchain-community) (2.14.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/dazzpool/anaconda3/envs/atsResume/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Building wheels for collected packages: faiss-cpu\n",
      "  Building wheel for faiss-cpu (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31mÃ—\u001b[0m \u001b[32mBuilding wheel for faiss-cpu \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31mâ•°â”€>\u001b[0m \u001b[31m[8 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'faiss._swigfaiss' extension\n",
      "  \u001b[31m   \u001b[0m swigging faiss/faiss/python/swigfaiss.i to faiss/faiss/python/swigfaiss_wrap.cpp\n",
      "  \u001b[31m   \u001b[0m swig -python -c++ -Doverride= -I/usr/local/include -Ifaiss -doxygen -module swigfaiss -o faiss/faiss/python/swigfaiss_wrap.cpp faiss/faiss/python/swigfaiss.i\n",
      "  \u001b[31m   \u001b[0m error: command 'swig' failed: No such file or directory\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for faiss-cpu\u001b[0m\u001b[31m\n",
      "\u001b[0mFailed to build faiss-cpu\n",
      "\u001b[31mERROR: Could not build wheels for faiss-cpu, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install langchain-community faiss-cpu langchain-openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atsResume",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
